datamodule:
  _target_: 'classy.data.data_modules.ClassyDataModule'
  task: ${task}
  dataset_path: null  # set via kwargs
  dataset:
    _target_: 'classy.data.dataset.hf.classification.HFTokenDataset.from_file'
    transformer_model: ${transformer_model}
    truncation: true
    additional_special_tokens: "${oc.select:'model.additional_special_tokens',${oc.decode:'[]'}}"
    min_length: 5
    max_length: 512
    tokens_per_batch: 1000
    max_batch_size: 16
    section_size: 10000
    prebatch: True
    materialize: False
    for_inference: False
  validation_dataset: "${adapt_dataset_from:${data.datamodule.dataset},validation}"
  validation_split_size: 0.1
  test_split_size: 0.1
  max_nontrain_split_size: 10000
  shuffle_dataset: True
