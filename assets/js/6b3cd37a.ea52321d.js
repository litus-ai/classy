"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9465],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>h});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var m=n.createContext({}),p=function(e){var t=n.useContext(m),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=p(e.components);return n.createElement(m.Provider,{value:t},e.children)},s={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,m=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),u=p(a),h=r,k=u["".concat(m,".").concat(h)]||u[h]||s[h]||l;return a?n.createElement(k,i(i({ref:t},d),{},{components:a})):n.createElement(k,i({ref:t},d))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=u;var o={};for(var m in t)hasOwnProperty.call(t,m)&&(o[m]=t[m]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var p=2;p<l;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},9825:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>m,contentTitle:()=>i,default:()=>s,frontMatter:()=>l,metadata:()=>o,toc:()=>p});var n=a(7462),r=(a(7294),a(3905));const l={sidebar_position:3,title:"Default Profiles"},i=void 0,o={unversionedId:"reference-manual/profiles",id:"reference-manual/profiles",title:"Default Profiles",description:"As you have seen from the previous tutorials, your systems are fully customizable in classy.",source:"@site/docs/reference-manual/profiles.md",sourceDirName:"reference-manual",slug:"/reference-manual/profiles",permalink:"/classy/docs/reference-manual/profiles",draft:!1,editUrl:"https://github.com/sunglasses-ai/classy/edit/main/docs/docs/reference-manual/profiles.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,title:"Default Profiles"},sidebar:"tutorialSidebar",previous:{title:"Tasks and Input Formats",permalink:"/classy/docs/reference-manual/tasks-and-formats"},next:{title:"Mixins",permalink:"/classy/docs/reference-manual/mixins"}},m={},p=[{value:"distilbert \ud83c\udf33 \ud83d\ude80",id:"distilbert--",level:2},{value:"General Info",id:"general-info",level:5},{value:"Model and Optimization",id:"model-and-optimization",level:5},{value:"Train command",id:"train-command",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile",level:5},{value:"distilroberta \ud83c\udf33 \ud83d\ude80",id:"distilroberta--",level:2},{value:"General Info",id:"general-info-1",level:5},{value:"Model and Optimization",id:"model-and-optimization-1",level:5},{value:"Train command",id:"train-command-1",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-1",level:5},{value:"squeezebert \ud83c\udf33 \ud83d\ude80",id:"squeezebert--",level:2},{value:"General Info",id:"general-info-2",level:5},{value:"Model and Optimization",id:"model-and-optimization-2",level:5},{value:"Train command",id:"train-command-2",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-2",level:5},{value:"bert-base \ud83c\udf32 \ud83d\ude84",id:"bert-base--",level:2},{value:"General Info",id:"general-info-3",level:5},{value:"Model and Optimization",id:"model-and-optimization-3",level:5},{value:"Train command",id:"train-command-3",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-3",level:5},{value:"gpt2 \ud83c\udf32 \ud83d\ude84",id:"gpt2--",level:2},{value:"General Info",id:"general-info-4",level:5},{value:"Model and Optimization",id:"model-and-optimization-4",level:5},{value:"Train command",id:"train-command-4",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-4",level:5},{value:"roberta-base \ud83c\udf32 \ud83d\ude84",id:"roberta-base--",level:2},{value:"General Info",id:"general-info-5",level:5},{value:"Model and Optimization",id:"model-and-optimization-5",level:5},{value:"Train command",id:"train-command-5",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-5",level:5},{value:"deberta-base \ud83c\udf32 \ud83d\ude84",id:"deberta-base--",level:2},{value:"General Info",id:"general-info-6",level:5},{value:"Model and Optimization",id:"model-and-optimization-6",level:5},{value:"Train command",id:"train-command-6",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-6",level:5},{value:"bart-base \ud83c\udf32 \ud83d\ude84",id:"bart-base--",level:2},{value:"General Info",id:"general-info-7",level:5},{value:"Model and Optimization",id:"model-and-optimization-7",level:5},{value:"Train command",id:"train-command-7",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-7",level:5},{value:"multilingual-bert \ud83c\udf32 \ud83d\ude84 \ud83c\udf0f",id:"multilingual-bert---",level:2},{value:"General Info",id:"general-info-8",level:5},{value:"Model and Optimization",id:"model-and-optimization-8",level:5},{value:"Train command",id:"train-command-8",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-8",level:5},{value:"xlm-roberta-base \ud83c\udf32 \ud83d\ude84 \ud83c\udf0f",id:"xlm-roberta-base---",level:2},{value:"General Info",id:"general-info-9",level:5},{value:"Model and Optimization",id:"model-and-optimization-9",level:5},{value:"Train command",id:"train-command-9",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-9",level:5},{value:"bert-large \ud83c\udf35 \ud83d\ude9c",id:"bert-large--",level:2},{value:"General Info",id:"general-info-10",level:5},{value:"Model and Optimization",id:"model-and-optimization-10",level:5},{value:"Train command",id:"train-command-10",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-10",level:5},{value:"roberta-large \ud83c\udf35 \ud83d\ude9c",id:"roberta-large--",level:2},{value:"General Info",id:"general-info-11",level:5},{value:"Model and Optimization",id:"model-and-optimization-11",level:5},{value:"Train command",id:"train-command-11",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-11",level:5},{value:"deberta-large \ud83c\udf35 \ud83d\ude9c",id:"deberta-large--",level:2},{value:"General Info",id:"general-info-12",level:5},{value:"Model and Optimization",id:"model-and-optimization-12",level:5},{value:"Train command",id:"train-command-12",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-12",level:5},{value:"xlm-roberta-large \ud83c\udf35 \ud83d\ude9c \ud83c\udf0f",id:"xlm-roberta-large---",level:2},{value:"General Info",id:"general-info-13",level:5},{value:"Model and Optimization",id:"model-and-optimization-13",level:5},{value:"Train command",id:"train-command-13",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-13",level:5},{value:"gpt2-medium \ud83c\udf35 \ud83d\ude9c",id:"gpt2-medium--",level:2},{value:"General Info",id:"general-info-14",level:5},{value:"Model and Optimization",id:"model-and-optimization-14",level:5},{value:"Train command",id:"train-command-14",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-14",level:5},{value:"bart-large \ud83c\udf35 \ud83d\ude9c",id:"bart-large--",level:2},{value:"General Info",id:"general-info-15",level:5},{value:"Model and Optimization",id:"model-and-optimization-15",level:5},{value:"Train command",id:"train-command-15",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-15",level:5},{value:"mbart \ud83c\udf35 \ud83c\udfd7\ufe0f \ud83c\udf0f",id:"mbart--\ufe0f-",level:2},{value:"General Info",id:"general-info-16",level:5},{value:"Model and Optimization",id:"model-and-optimization-16",level:5},{value:"Train command",id:"train-command-16",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-16",level:5},{value:"gpt2-large \ud83c\udf35 \ud83c\udfd7\ufe0f",id:"gpt2-large--\ufe0f",level:2},{value:"General Info",id:"general-info-17",level:5},{value:"Model and Optimization",id:"model-and-optimization-17",level:5},{value:"Train command",id:"train-command-17",level:5},{value:"When should I use this profile?",id:"when-should-i-use-this-profile-17",level:5}],d={toc:p};function s(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"As you have seen from the previous tutorials, your systems are fully customizable in ",(0,r.kt)("inlineCode",{parentName:"p"},"classy"),".\nEven if we strongly encourage you to create you own configurations, we provide a set of predefined and well-established profiles\nthat will work with competitive performances in almost all setting and scenarios."),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"To use a profile, you just have to pass the profile name to the parameter ",(0,r.kt)("inlineCode",{parentName:"p"},"--profile")," at training time"),(0,r.kt)("pre",{parentName:"admonition"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train <task> <dataset-path> -n <model-name> --profile <profile_name>\n"))),(0,r.kt)("h2",{id:"distilbert--"},"distilbert \ud83c\udf33 \ud83d\ude80"),(0,r.kt)("h5",{id:"general-info"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 4GB")))),(0,r.kt)("h5",{id:"model-and-optimization"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"DistilBERT")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1910.01108"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/distilbert.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"Adafactor")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1804.04235"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/main_classes/optimizer_schedules.html#adafactor-pytorch"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile distilbert\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"blazing fast")," training and inference"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Quick run")," to evaluate your dataset and check for possible flaws"),(0,r.kt)("li",{parentName:"ul"},"You don't have at your disposal a GPU with more than 4GB VRAM"),(0,r.kt)("li",{parentName:"ul"},"You will use the model in ",(0,r.kt)("strong",{parentName:"li"},"low energy consumption")," scenarios")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"distilroberta--"},"distilroberta \ud83c\udf33 \ud83d\ude80"),(0,r.kt)("h5",{id:"general-info-1"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 4GB")))),(0,r.kt)("h5",{id:"model-and-optimization-1"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"DistilRoBERTa")," (\ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/distilroberta-base"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"Adafactor")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1804.04235"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/main_classes/optimizer_schedules.html#adafactor-pytorch"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-1"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile distilroberta\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-1"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"blazing fast")," training and inference"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Quick run")," to evaluate your dataset and check for possible flaws"),(0,r.kt)("li",{parentName:"ul"},"You don't have at your disposal a GPU with more than 4GB VRAM"),(0,r.kt)("li",{parentName:"ul"},"You will use the model in ",(0,r.kt)("strong",{parentName:"li"},"low energy consumption")," scenarios")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"squeezebert--"},"squeezebert \ud83c\udf33 \ud83d\ude80"),(0,r.kt)("h5",{id:"general-info-2"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 4GB")))),(0,r.kt)("h5",{id:"model-and-optimization-2"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"SqueezeBERT")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/2006.11316"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/squeezebert.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"Adafactor")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1804.04235"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/main_classes/optimizer_schedules.html#adafactor-pytorch"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-2"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile squeezebert\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-2"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"blazing fast")," training and inference"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Quick run")," to evaluate your dataset and check for possible flaws"),(0,r.kt)("li",{parentName:"ul"},"You don't have at your disposal a GPU with more than 4GB VRAM"),(0,r.kt)("li",{parentName:"ul"},"You will use the model in ",(0,r.kt)("strong",{parentName:"li"},"low energy consumption")," scenarios")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"bert-base--"},"bert-base \ud83c\udf32 \ud83d\ude84"),(0,r.kt)("h5",{id:"general-info-3"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,r.kt)("h5",{id:"model-and-optimization-3"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"BERT-base")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://aclanthology.org/N19-1423"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bert.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"AdamW")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-3"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile bert-base\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-3"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"well-established model")," for everyday use"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,r.kt)("li",{parentName:"ul"},"You will use the model in ",(0,r.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"gpt2--"},"gpt2 \ud83c\udf32 \ud83d\ude84"),(0,r.kt)("h5",{id:"general-info-4"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"generation")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,r.kt)("h5",{id:"model-and-optimization-4"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"GPT2")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/gpt2.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"Adam")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1412.6980"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.Adam.html"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-4"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [generation] my_dataset_path -n my_model --profile gpt2\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-4"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want an affordable (decoder-only) ",(0,r.kt)("strong",{parentName:"li"},"generative model")," for English"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,r.kt)("li",{parentName:"ul"},"You will use the model in ",(0,r.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"roberta-base--"},"roberta-base \ud83c\udf32 \ud83d\ude84"),(0,r.kt)("h5",{id:"general-info-5"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,r.kt)("h5",{id:"model-and-optimization-5"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"RoBERTa-base")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1907.11692"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bert.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"AdamW")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-5"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile bert-base\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-5"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"well-established model")," for everyday use"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,r.kt)("li",{parentName:"ul"},"You will use the model in ",(0,r.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"deberta-base--"},"deberta-base \ud83c\udf32 \ud83d\ude84"),(0,r.kt)("h5",{id:"general-info-6"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,r.kt)("h5",{id:"model-and-optimization-6"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"DeBERTa-base")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/2006.03654"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/deberta.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"RAdam")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/pdf/1908.03265v3.pdf"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://github.com/LiyuanLucasLiu/RAdam"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-6"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile deberta-base\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-6"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"recently released model with state-of-the-art performances")," on several NLU benchmarks"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,r.kt)("li",{parentName:"ul"},"You will use the model in ",(0,r.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"bart-base--"},"bart-base \ud83c\udf32 \ud83d\ude84"),(0,r.kt)("h5",{id:"general-info-7"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")," ",(0,r.kt)("inlineCode",{parentName:"td"},"generation")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,r.kt)("h5",{id:"model-and-optimization-7"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"Bart-base")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1910.13461"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bart.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"RAdam")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/pdf/1908.03265v3.pdf"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://github.com/LiyuanLucasLiu/RAdam"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-7"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa|generation] my_dataset_path -n my_model --profile bart-base\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-7"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,r.kt)("li",{parentName:"ul"},"You want to tackle an English generation task with an affordable model"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,r.kt)("li",{parentName:"ul"},"You will use the model in ",(0,r.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"multilingual-bert---"},"multilingual-bert \ud83c\udf32 \ud83d\ude84 \ud83c\udf0f"),(0,r.kt)("h5",{id:"general-info-8"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"104 (",(0,r.kt)("a",{parentName:"td",href:"https://github.com/google-research/bert/blob/master/multilingual.md"},"Complete List"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,r.kt)("h5",{id:"model-and-optimization-8"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"mBERT")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://aclanthology.org/N19-1423"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bert.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"AdamW")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-8"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile multilingual-bert\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-8"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You require a ",(0,r.kt)("strong",{parentName:"li"},"multilingual model")," covering languages other than English"),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"well-established model")," for everyday use"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,r.kt)("li",{parentName:"ul"},"You will use the model in ",(0,r.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"xlm-roberta-base---"},"xlm-roberta-base \ud83c\udf32 \ud83d\ude84 \ud83c\udf0f"),(0,r.kt)("h5",{id:"general-info-9"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"100 (Complete list in the reference paper)"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 8GB")))),(0,r.kt)("h5",{id:"model-and-optimization-9"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"XLM-RoBERTa-base")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1911.02116"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/xlmroberta.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"AdamW")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-9"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile xlm-roberta-base\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-9"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You require a state-of-the-art ",(0,r.kt)("strong",{parentName:"li"},"multilingual model")," covering languages other than English"),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"trade-off between training/inference speed and model performances")),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"well-established model")," for everyday use"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 8GB of VRAM"),(0,r.kt)("li",{parentName:"ul"},"You will use the model in ",(0,r.kt)("strong",{parentName:"li"},"moderate energy consumption")," scenarios")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"bert-large--"},"bert-large \ud83c\udf35 \ud83d\ude9c"),(0,r.kt)("h5",{id:"general-info-10"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 11GB (fp16)")))),(0,r.kt)("h5",{id:"model-and-optimization-10"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"BERT-large")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://aclanthology.org/N19-1423"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bert.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"AdamW")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-10"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile bert-large --fp16\n")),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"Remember to use the ",(0,r.kt)("inlineCode",{parentName:"p"},"--fp16")," at training time or otherwise the model may not fit in memory.")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-10"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want state-of-the-art performances, ",(0,r.kt)("strong",{parentName:"li"},"no compromise!")),(0,r.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"well-established model")," used by thousands of users"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,r.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"roberta-large--"},"roberta-large \ud83c\udf35 \ud83d\ude9c"),(0,r.kt)("h5",{id:"general-info-11"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 11GB (fp16)")))),(0,r.kt)("h5",{id:"model-and-optimization-11"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"RoBERTa-large")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1907.11692"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bert.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"AdamW")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-11"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile roberta-large --fp16\n")),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"Remember to use the ",(0,r.kt)("inlineCode",{parentName:"p"},"--fp16")," at training time or otherwise the model may not fit in memory.")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-11"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want state-of-the-art performances, ",(0,r.kt)("strong",{parentName:"li"},"no compromise!")),(0,r.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"well-established model")," used by thousands of users"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,r.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"deberta-large--"},"deberta-large \ud83c\udf35 \ud83d\ude9c"),(0,r.kt)("h5",{id:"general-info-12"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 11GB (fp16)")))),(0,r.kt)("h5",{id:"model-and-optimization-12"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"DeBERTa-large")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/2006.03654"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/deberta.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"RAdam")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/pdf/1908.03265v3.pdf"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://github.com/LiyuanLucasLiu/RAdam"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-12"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile deberta-large --fp16\n")),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"Remember to use the ",(0,r.kt)("inlineCode",{parentName:"p"},"--fp16")," at training time or otherwise the model may not fit in memory.")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-12"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want state-of-the-art performances, ",(0,r.kt)("strong",{parentName:"li"},"no compromise!")),(0,r.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,r.kt)("li",{parentName:"ul"},"You want ",(0,r.kt)("strong",{parentName:"li"},"one of the latest released SotA models")),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,r.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"xlm-roberta-large---"},"xlm-roberta-large \ud83c\udf35 \ud83d\ude9c \ud83c\udf0f"),(0,r.kt)("h5",{id:"general-info-13"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")),(0,r.kt)("td",{parentName:"tr",align:"center"},"100 (Complete list in the reference paper)"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 16GB (fp16)")))),(0,r.kt)("h5",{id:"model-and-optimization-13"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"XLM-RoBERTa-large")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1911.02116"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/xlmroberta.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"AdamW")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-13"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile xlm-roberta-large --fp16\n")),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"Remember to use the ",(0,r.kt)("inlineCode",{parentName:"p"},"--fp16")," at training time or otherwise the model may not fit in memory.")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-13"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You require a state-of-the-art ",(0,r.kt)("strong",{parentName:"li"},"multilingual model")," covering languages other than English, with ",(0,r.kt)("strong",{parentName:"li"},"no compromise")),(0,r.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"well-established model")," used by thousands of users"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,r.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"gpt2-medium--"},"gpt2-medium \ud83c\udf35 \ud83d\ude9c"),(0,r.kt)("h5",{id:"general-info-14"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"generation")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 11GB (fp16)")))),(0,r.kt)("h5",{id:"model-and-optimization-14"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"GPT2")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/gpt2.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"AdamW")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-14"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [generation] my_dataset_path -n my_model --profile gpt2-medium\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-14"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want a medium (decoder-only) ",(0,r.kt)("strong",{parentName:"li"},"generative model")," for English"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,r.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"bart-large--"},"bart-large \ud83c\udf35 \ud83d\ude9c"),(0,r.kt)("h5",{id:"general-info-15"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")," ",(0,r.kt)("inlineCode",{parentName:"td"},"generation")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 11GB (fp16)")))),(0,r.kt)("h5",{id:"model-and-optimization-15"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"Bart-large")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1910.13461"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/bart.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"RAdam")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/pdf/1908.03265v3.pdf"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://github.com/LiyuanLucasLiu/RAdam"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-15"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa|generation] my_dataset_path -n my_model --profile bart-large\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-15"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want state-of-the-art performances, especially on English generation problems, with ",(0,r.kt)("strong",{parentName:"li"},"no compromise!")),(0,r.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"well-established model")," used by thousands of users"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 11GB of VRAM that supports fp16 precision"),(0,r.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"mbart--\ufe0f-"},"mbart \ud83c\udf35 \ud83c\udfd7\ufe0f \ud83c\udf0f"),(0,r.kt)("h5",{id:"general-info-16"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"sequence")," ",(0,r.kt)("inlineCode",{parentName:"td"},"sentence-pair")," ",(0,r.kt)("inlineCode",{parentName:"td"},"token")," ",(0,r.kt)("inlineCode",{parentName:"td"},"qa")," ",(0,r.kt)("inlineCode",{parentName:"td"},"generation")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 24GB (fp16)")))),(0,r.kt)("h5",{id:"model-and-optimization-16"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"mBART")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/2001.08210"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/mbart.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"RAdam")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/pdf/1908.03265v3.pdf"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://github.com/LiyuanLucasLiu/RAdam"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-16"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [sequence|sentence-pair|token|qa] my_dataset_path -n my_model --profile bart-base\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-16"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want a state-of-the-art ",(0,r.kt)("strong",{parentName:"li"},"multilingual model"),", covering 25 languages and particularly suited for ",(0,r.kt)("strong",{parentName:"li"},"generation tasks")," (e.g. machine translation), with ",(0,r.kt)("strong",{parentName:"li"},"no compromise")),(0,r.kt)("li",{parentName:"ul"},"You want to show how far you can go with the proper infrastructure"),(0,r.kt)("li",{parentName:"ul"},"You want a ",(0,r.kt)("strong",{parentName:"li"},"well-established model")," used by thousands of users"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 24GB of VRAM that supports fp16 precision"),(0,r.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"gpt2-large--\ufe0f"},"gpt2-large \ud83c\udf35 \ud83c\udfd7\ufe0f"),(0,r.kt)("h5",{id:"general-info-17"},"General Info"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Tasks"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Supported Languages"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Required VRAM"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("inlineCode",{parentName:"td"},"generation")),(0,r.kt)("td",{parentName:"tr",align:"center"},"English"),(0,r.kt)("td",{parentName:"tr",align:"center"},"< 24GB (fp16)")))),(0,r.kt)("h5",{id:"model-and-optimization-17"},"Model and Optimization"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Model"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Optimizer"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"GPT2")," (\ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf"},"Paper")," ","|"," \ud83d\udd28 ",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/transformers/model_doc/gpt2.html"},"Implementation"),")"),(0,r.kt)("td",{parentName:"tr",align:"center"},(0,r.kt)("u",null,"AdamW")," (",(0,r.kt)("a",{parentName:"td",href:"https://arxiv.org/abs/1711.05101"},"Paper")," \ud83d\udcc4 ",(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"},"Implementation")," \ud83d\udd28)")))),(0,r.kt)("h5",{id:"train-command-17"},"Train command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"classy train [generation] my_dataset_path -n my_model --profile gpt2-large\n")),(0,r.kt)("h5",{id:"when-should-i-use-this-profile-17"},"When should I use this profile?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"You want a large (decoder-only) ",(0,r.kt)("strong",{parentName:"li"},"generative model")," for English"),(0,r.kt)("li",{parentName:"ul"},"You have at your disposal a GPU with at least 24GB of VRAM that supports fp16 precision"),(0,r.kt)("li",{parentName:"ul"},"You don't have any energy consumption restriction")))}s.isMDXComponent=!0}}]);